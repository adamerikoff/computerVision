{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/adamerik/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/adamerik/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pseudo code for the text classification task\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_list(folder_path):\n",
    "    temp_list = []\n",
    "    txt_files = os.listdir(folder_path)\n",
    "    for txt_file in txt_files:\n",
    "        with open(os.path.join(folder_path, txt_file), 'r', encoding='utf-8') as file:\n",
    "            text_data = file.read()\n",
    "            temp_list.append(text_data)\n",
    "    return temp_list\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text (you can replace this with your tokenizer)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "\n",
    "    # Remove stopwords\n",
    "    nltk_stopwords = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in nltk_stopwords]\n",
    "\n",
    "    # Stem the tokens\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    # Remove special characters and numbers\n",
    "    tokens = [re.sub(r'[^a-zA-Z]', '', token) for token in tokens]\n",
    "\n",
    "    # Remove empty tokens\n",
    "    tokens = [token for token in tokens if token != '']\n",
    "\n",
    "    # Join tokens back into a single string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data load\n",
    "banks_folder_path = \"./train/banks\"\n",
    "oilgas_folder_path = \"./train/oilgas\"\n",
    "pharma_folder_path = \"./train/pharma\"\n",
    "\n",
    "banks_df = pd.DataFrame(txt_to_list(banks_folder_path))\n",
    "oilgas_df = pd.DataFrame(txt_to_list(oilgas_folder_path))\n",
    "pharma_df = pd.DataFrame(txt_to_list(pharma_folder_path))\n",
    "\n",
    "banks_df[\"class\"] = \"banks\"\n",
    "oilgas_df[\"class\"] = \"oilgas\"\n",
    "pharma_df[\"class\"] = \"pharma\"\n",
    "\n",
    "train_df = pd.concat([banks_df, oilgas_df, pharma_df])\n",
    "train_df = train_df.rename(columns={0: \"text\", 1: \"class\",})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62154.94117647059\n",
      "51593.17857142857\n",
      "53114.64705882353\n"
     ]
    }
   ],
   "source": [
    "train_df['word_count'] = train_df['text'].apply(lambda x: len(str(x).split()))\n",
    "print(train_df[train_df['class']==\"banks\"]['word_count'].mean()) #banks text\n",
    "print(train_df[train_df['class']==\"oilgas\"]['word_count'].mean()) #oilgas text\n",
    "print(train_df[train_df['class']==\"pharma\"]['word_count'].mean()) #pharma text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['text'] = train_df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['preprocessed_text'] = train_df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>word_count</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>united states securities and exchange commiss...</td>\n",
       "      <td>banks</td>\n",
       "      <td>62149</td>\n",
       "      <td>unit state secur exchang commiss washington dc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>united states securities and exchange commiss...</td>\n",
       "      <td>banks</td>\n",
       "      <td>45035</td>\n",
       "      <td>unit state secur exchang commiss washington dc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>united states securities and exchange commiss...</td>\n",
       "      <td>banks</td>\n",
       "      <td>47117</td>\n",
       "      <td>unit state secur exchang commiss washington dc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\t \\t \\t\\t \\t\\t\\t table of contents \\t\\t \\t\\t...</td>\n",
       "      <td>banks</td>\n",
       "      <td>60182</td>\n",
       "      <td>tabl content unit state ecur exchang commiss w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\t \\t united states securities and exchange c...</td>\n",
       "      <td>banks</td>\n",
       "      <td>86034</td>\n",
       "      <td>unit state secur exchang commiss washington dc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>united states securities and exchange commiss...</td>\n",
       "      <td>pharma</td>\n",
       "      <td>16682</td>\n",
       "      <td>unit state secur exchang commiss washington dc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>united states securities and exchange commiss...</td>\n",
       "      <td>pharma</td>\n",
       "      <td>40623</td>\n",
       "      <td>unit state secur exchang commiss washington dc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>united states securities and exchange commiss...</td>\n",
       "      <td>pharma</td>\n",
       "      <td>72965</td>\n",
       "      <td>unit state secur exchang commiss washington dc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>united states securities and exchange commiss...</td>\n",
       "      <td>pharma</td>\n",
       "      <td>36244</td>\n",
       "      <td>unit state secur exchang commiss washington dc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>table of contents united states securities an...</td>\n",
       "      <td>pharma</td>\n",
       "      <td>67882</td>\n",
       "      <td>tabl content unit state secur exchang commiss ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text   class  word_count   \n",
       "0    united states securities and exchange commiss...   banks       62149  \\\n",
       "1    united states securities and exchange commiss...   banks       45035   \n",
       "2    united states securities and exchange commiss...   banks       47117   \n",
       "3    \\t \\t \\t\\t \\t\\t\\t table of contents \\t\\t \\t\\t...   banks       60182   \n",
       "4    \\t \\t united states securities and exchange c...   banks       86034   \n",
       "..                                                ...     ...         ...   \n",
       "29   united states securities and exchange commiss...  pharma       16682   \n",
       "30   united states securities and exchange commiss...  pharma       40623   \n",
       "31   united states securities and exchange commiss...  pharma       72965   \n",
       "32   united states securities and exchange commiss...  pharma       36244   \n",
       "33   table of contents united states securities an...  pharma       67882   \n",
       "\n",
       "                                    preprocessed_text  \n",
       "0   unit state secur exchang commiss washington dc...  \n",
       "1   unit state secur exchang commiss washington dc...  \n",
       "2   unit state secur exchang commiss washington dc...  \n",
       "3   tabl content unit state ecur exchang commiss w...  \n",
       "4   unit state secur exchang commiss washington dc...  \n",
       "..                                                ...  \n",
       "29  unit state secur exchang commiss washington dc...  \n",
       "30  unit state secur exchang commiss washington dc...  \n",
       "31  unit state secur exchang commiss washington dc...  \n",
       "32  unit state secur exchang commiss washington dc...  \n",
       "33  tabl content unit state secur exchang commiss ...  \n",
       "\n",
       "[96 rows x 4 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(data_path):\n",
    "    # Implement text preprocessing, such as tokenization, vectorization, etc.\n",
    "    pass\n",
    "\n",
    "def train_linear_classifier(X_train, y_train):\n",
    "    # Implement training of linear classifier\n",
    "    pass\n",
    "\n",
    "def validate_classifier(model, X_val, y_val):\n",
    "    # Test the classifier on validation set\n",
    "    pass\n",
    "\n",
    "def test_classifier(model, X_test):\n",
    "    # Make predictions with the trained model on test set\n",
    "    pass\n",
    "\n",
    "def save_predictions(predictions, output_path):\n",
    "    # Save the predictions to a file\n",
    "    pass\n",
    "\n",
    "def main():\n",
    "    # Step 1: Preprocessing data\n",
    "    X_train, y_train = preprocess_text(\"path/to/train/your_chosen_category/\")\n",
    "    X_val, y_val = preprocess_text(\"path/to/validation/your_chosen_category/\")\n",
    "    X_test = preprocess_text(\"path/to/test/\")\n",
    "\n",
    "    # Step 2: Training a linear classifier\n",
    "    model = train_linear_classifier(X_train, y_train)\n",
    "\n",
    "    # Step 3: Validate the model performance\n",
    "    validate_classifier(model, X_val, y_val)\n",
    "\n",
    "    # Optional: Tune the model if validation results are not satisfactory\n",
    "\n",
    "    # Step 4: Test the model\n",
    "    predictions = test_classifier(model, X_test)\n",
    "\n",
    "    # Step 5: Save the predictions\n",
    "    save_predictions(predictions, \"path/to/output/predictions.txt\")\n",
    "\n",
    "    # Additional: Write a report documenting your process and findings\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
