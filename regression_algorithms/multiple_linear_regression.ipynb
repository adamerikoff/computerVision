{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression Regression Implementation\n",
    "\n",
    "\n",
    "## 1. Considerations\n",
    "*__Multiple linear regression__ refers to a statistical technique that uses two or more independent variables to predict the outcome of a dependent variable. The technique enables analysts to determine the variation of the model and the relative contribution of each independent variable in the total variance. Multiple regression can take two forms, i.e., linear regression and non-linear regression.*<br>\n",
    "\n",
    "*Polynomial Regression is a special case of Linear Regression where we fit the polynomial equation on the data with a curvilinear relationship between the dependent and independent variables.*\n",
    "\n",
    "$$\n",
    "    y_i = b_0 + b_1x_1 + b_2x_2 + ... + b_i x_i + error\n",
    "$$\n",
    "\n",
    "__Advantages of Polynomial Regression__\n",
    "- The most important advantage of Multivariate regression is it helps us to understand the relationships among variables present in the dataset. This will further help in understanding the correlation between dependent and independent variables. Multivariate linear regression is a widely used machine learning algorithm.\n",
    "\n",
    "__Disadvantage of Polynomial Regression__\n",
    "- Multivariate techniques are a bit complex and require a high-levels of mathematical calculation. \n",
    "- The multivariate regression model’s output is not easy to interpret sometimes, because it has some loss and error output which are not identical.\n",
    "- This model does not have much scope for smaller datasets. Hence, the same cannot be applied to them. The results are better for larger datasets.\n",
    "\n",
    "\n",
    "#### 1.2 Choses mathématiques\n",
    "$$\n",
    "b \\: = \\: coefs\n",
    "$$\n",
    "$$\n",
    "x = parameters\n",
    "$$\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "y_1\\\\\n",
    "y_2\\\\\n",
    "y_3\\\\\n",
    "y_4\\\\\n",
    "y_5\\\\\n",
    "... \\\\\n",
    "y_n \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "x_{11} & x_{12} & ... & x_{1m} \\\\\n",
    "x_{21} & x_{22} & ... & x_{2m} \\\\\n",
    "x_{31} & x_{32} & ... & x_{3m} \\\\\n",
    "x_{41} & x_{42} & ... & x_{4m} \\\\\n",
    "x_{51} & x_{52} & ... & x_{5m} \\\\\n",
    "... & ... & ... & ...\\\\\n",
    "x_{n1} & x_{n2} & ... & x_{nm} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "b_1 \\\\\n",
    "b_2 \\\\\n",
    "b_3 \\\\\n",
    "b_4 \\\\\n",
    "b_5 \\\\\n",
    "... \\\\\n",
    "b_n \\\\\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "error_1 \\\\\n",
    "error_2 \\\\\n",
    "error_3 \\\\\n",
    "error_4 \\\\\n",
    "error_5 \\\\\n",
    "... \\\\\n",
    "error_n \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$ERR = Y - Xb \\rightarrow ERR^T ERR = (Y-Xb)^T(Y-Xb)$$\n",
    "$$ERR^T ERR = (Y-Xb)^T(Y-Xb)$$\n",
    "$$ERR^T ERR = (Y^T-b^TX^T)(Y-Xb)$$\n",
    "$$ERR^T ERR = Y^Y - Y^TXb - b^TX^TY + b^TX^TXb$$\n",
    "$$ERR^T ERR = Y^Y - 2Y^TXb + b^TX^TXb$$\n",
    "$$note \\: that \\: b^TX^TY = (b^TX^TY)^T = Y^TXb $$\n",
    "$$\\frac{\\partial (ERR^T ERR)}{\\partial b} = \\frac{\\partial (Y^Y - 2Y^TXb + b^TX^TXb)}{\\partial b}$$\n",
    "$$0 = -2X^TY + 2X^TXB$$\n",
    "$$B = (X^TX)^{-1}X^TY$$\n",
    "#### 1.3 NumPy Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/kc_house_data.csv\")\n",
    "data.insert(loc=0, column='A', value=1)\n",
    "Y = data[\"price\"].to_numpy()\n",
    "X = data[[\"A\", \"bedrooms\", \"bathrooms\", \"yr_built\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$B = (X^TX)^{-1}X^TY$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilinear_regression(X,Y):\n",
    "    B = np.dot(np.linalg.inv(np.dot(X.T, X)),np.dot(X.T,Y))\n",
    "    return B\n",
    "\n",
    "def polynomial_regression_predict(X, B):\n",
    "    return np.dot(X,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUSTOM COEFS: [ 7.16597718e+06  2.60871594e+03  3.17050430e+05 -3.70828359e+03]\n",
      "SKLEARN COEFS: [     0.           2608.71594022 317050.42962814  -3708.28358646]\n",
      "\n",
      "\n",
      "\n",
      "Mean_Squared_Error SKLearn: 91529101733.40758\n",
      "r_square_value SKLearn: 0.33355428196639025\n",
      "\n",
      "\n",
      "Mean_Squared_Error Custom: 91529101733.40001\n",
      "r_square_value Custom: 0.3335542819664453\n"
     ]
    }
   ],
   "source": [
    "x_train = X[:int(len(X)*0.8)]\n",
    "x_test = X[int(len(X)*0.8):]\n",
    "y_train = Y[:int(len(Y)*0.8)]\n",
    "y_test = Y[int(len(Y)*0.8):]\n",
    "\n",
    "# Calculate slope and intercept using custom regression\n",
    "B = multilinear_regression(x_train,y_train)\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(f\"CUSTOM COEFS: {B}\")\n",
    "print(f\"SKLEARN COEFS: {model.coef_}\\n\\n\\n\")\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print('Mean_Squared_Error SKLearn:' ,mse)\n",
    "print('r_square_value SKLearn:',r_squared)\n",
    "\n",
    "mse = mean_squared_error(y_test, polynomial_regression_predict(x_test, B))\n",
    "r_squared = r2_score(y_test, polynomial_regression_predict(x_test, B))\n",
    "print('\\n\\nMean_Squared_Error Custom:' ,mse)\n",
    "print('r_square_value Custom:',r_squared)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
